library(tidyverse); library(MASS); library(lmtest)
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~ -1 + Type.1 + HP + Attack + Defense + Sp..Atk + Sp..Def + Speed + Generation ,data=train,family="binomial")
probs<-predict(fit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
apply(diags,2,mean)
cv<-cv.glmnet(x,y,family = "binomial")
lasso<-glmnet(x,y,family = 'binomial', lambda=cv$lambda.1se)
coef(lasso)
set.seed(1234)
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~. ,family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
set.seed(1234)
k=10
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~. ,family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
set.seed(1234)
k=5
data1<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
class_diag(lasso, poke$Legendary)
problas<- predict(lasso, type = "response")
problas<- predict(lasso, type = "response")
problas<- predict(cv, type = "response")
data2<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data2[folds!=i,]
test<-data2[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
set.seed(1234)
k=10
data2<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data2[folds!=i,]
test<-data2[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~ -1 + ., family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
set.seed(1234)
k=10
data2<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data2[folds!=i,]
test<-data2[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., data = poke, family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)
data2<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data2[folds!=i,]
test<-data2[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., data = train, family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)
table(predict=as.numeric(prob>.5),truth=poke$Legendary)%>%addmargins
table(predict=as.numeric(prob>.5),truth)%>%addmargins
table(predict=as.numeric(prob>.5),truth = test$Legendary)%>%addmargins
table(predict=preds,truth = test$Legendary)%>%addmargins
poke1e <- poke %>% select(X., Type.1, Total, Sp..Atk, Sp..Def, Speed) %>% filter(Type.1 %in% c("Flying", "Psychic"))
y<- as.matrix(poke$Legendary)
fit1
x<- model.matrix(fit1)[,-1]
x
cv<-cv.glmnet(x,y,family = "binomial")
lasso<-glmnet(x,y,family = 'binomial', lambda=cv$lambda.1se)
coef(lasso)
poke1e <- poke %>% select(Type.1, HP, Attack, Sp..Atk, Sp..Def, Speed, Generation) %>% filter(Type.1 %in% c("Flying", "Psychic"))
library(dplyr)
poke1e <- poke %>% select(Type.1, HP, Attack, Sp..Atk, Sp..Def, Speed, Generation) %>% filter(Type.1 %in% c("Flying", "Psychic"))
library(tidyverse)
View(poke)
poke1 <- poke %>% select(Type.1, HP, Attack, Sp..Atk, Sp..Def, Speed, Generation) %>% filter(Type.1 %in% c("Flying", "Psychic"))
poke1 <- poke %>% select(c(Type.1, HP, Attack, Sp..Atk, Sp..Def, Speed, Generation)) %>% filter(Type.1 %in% c("Flying", "Psychic"))
poke1 <- poke %>% select(-c(Type.2, Legendary)) %>% filter(Type.1 %in% c("Flying", "Psychic"))
poke1 <- poke %>% select(-Type.2, -Legendary) %>% filter(Type.1 %in% c("Flying", "Psychic"))
poke1e <- poke %>% select(X., Type.1, Total, Sp..Atk, Sp..Def, Speed) %>% filter(Type.1 %in% c("Flying", "Psychic"))
poke1e <- dplyr::select(poke,Speed)
poke1e <- dplyr::select(poke,Type.1, HP, Attack, Defense, Sp..Atk, Sp..Def, Speed, Generation)
poke1 <- dplyr::select(poke,Type.1, HP, Attack, Defense, Sp..Atk, Sp..Def, Speed, Generation)
poke1<- poke1%>% filter(Type.1 %in% c("Flying", "Psychic"))
set.seed(1234)
k=10
library(tidyverse); library(MASS); library(lmtest)
data1<-poke1[sample(nrow(poke1)),]
folds<-cut(seq(1:nrow(poke1)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~ -1 + Type.1 + HP + Attack + Defense + Sp..Atk + Sp..Def + Speed + Generation ,data=train,family="binomial")
probs<-predict(fit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
poke1 <- dplyr::select(poke,Type.1, HP, Attack, Defense, Sp..Atk, Sp..Def, Speed, Generation, Legendary)
poke1<- poke1%>% filter(Type.1 %in% c("Flying", "Psychic"))
set.seed(1234)
k=10
library(tidyverse); library(MASS); library(lmtest)
data1<-poke1[sample(nrow(poke1)),]
folds<-cut(seq(1:nrow(poke1)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~ -1 + Type.1 + HP + Attack + Defense + Sp..Atk + Sp..Def + Speed + Generation ,data=train,family="binomial")
probs<-predict(fit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
apply(diags,2,mean)
expand.grid(malig=malig, benign = benign)
malig<-c(.49, .36, .57, .53, .61, .66)
benign<-c(.41, .22, .26, .56, .31 ,.39)
#example of how to use expand.grid
expand.grid(lets=c("A","B","C"),nums=c(1,2,3))
#example of how to use outer()
outer(c(4,5,6),c(1,2,3),"-")
expand.grid(malig=malig, benign = benign)
31/36
wilcox.test(malig, benign)
library(tidyverse)
malignancy <- data.frame(malig = malig, benign= benign)
malignancy <- malignancy >%> pivot_longer(cols=c(malig, benign), names_to = 'status', values_to = 'probability')
library(tidyverse)
malignancy <- data.frame(malig = malig, benign= benign)
malignancy <- malignancy %>% pivot_longer(cols=c(malig, benign), names_to = 'status', values_to = 'probability')
library(ggplot2)
malignancy %>% ggplot(aes(x=probability, fill=status)) + geom_histogram()
maligs <- expand.grid(malig=malig, benign=benign)
table(predict=as.numeric(malignancy$probability>.2), truth=malignancy$status) %>%addmargins
tpr <- function(p)mean(dat[dat$label=="malig",]$probability>p)
fpr <- tpr<-function(p)mean(dat[dat$label=="benign",]$probability>p)
TPR <- sapply(cutoffs,tpr)
cutoffs<-c(.2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7)
tpr <- function(p)mean(dat[dat$label=="malig",]$probability>p)
fpr <- tpr<-function(p)mean(dat[dat$label=="benign",]$probability>p)
TPR <- sapply(cutoffs,tpr)
cutoffs<-c(.2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7)
tpr <- function(p)mean(malignancy[malignancy$status=="malig",]$probability>p)
fpr <- tpr<-function(p)mean(malignancy[malignancy$status=="benign",]$probability>p)
TPR <- sapply(cutoffs,tpr)
FPR <- sapply(cutoffs,fpr)
ROC1 <- data.frame(cutoffs,TPR,FPR,TP=TPR*13,FP=FPR*19)%>%arrange(desc(cutoffs))
ggplot(ROC1) + geom_path(aes(FPR,TPR),size=1.5) + geom_segment(aes(x=0,y=0,xend=1,yend=1),lty=2) + scale_x_continuous(limits=c(0,1))
class_diag(malignancy$probability,as.factor(malignancy$status))
table(predict=preds,truth = test$Legendary)%>%addmargins
y<- as.matrix(poke$Legendary)
fit1
x<- model.matrix(fit1)[,-1]
x
cv<-cv.glmnet(x,y,family = "binomial")
lasso<-glmnet(x,y,family = 'binomial', lambda=cv$lambda.1se)
coef(lasso)
set.seed(1234)
k=10
data2<-poke[sample(nrow(poke)),]
folds<-cut(seq(1:nrow(poke)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data2[folds!=i,]
test<-data2[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~., data = train, family="binomial")
probs<-predict(fit,newdata = test,type="response")
preds<-ifelse(probs>.5,1,0)
diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)
table(predict=preds,truth = test$Legendary)%>%addmargins
(71+4)/80
poke1 <- dplyr::select(poke,Type.1, HP, Attack, Defense, Sp..Atk, Sp..Def, Speed, Generation, Legendary)
poke1<- poke1%>% filter(Type.1 %in% c("Flying", "Psychic"))
set.seed(1234)
k=10
library(tidyverse); library(MASS); library(lmtest)
data1<-poke1[sample(nrow(poke1)),]
folds<-cut(seq(1:nrow(poke1)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$Legendary
fit<-glm(Legendary~ -1 + Type.1 + HP + Attack + Defense + Sp..Atk + Sp..Def + Speed + Generation ,data=train,family="binomial")
probs<-predict(fit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
apply(diags,2,mean)
#install.packages("randomForest")
library(randomForest)
#install.packages("randomForest")
library(randomForest)
#install.packages("randomForest")
library(randomForest)
#install.packages("randomForest")
library(randomForest)
Salaries <- read.csv("~/Downloads/Salaries.csv")
View(Salaries)
knitr::opts_chunk$set(echo = TRUE)
options(repos="https://cran.rstudio.com")
a1 <- available.packages()
a1[a1[,"Package"]=="nlme",]
sessionInfo()
data(Salaries)
glimpse(Salaries)
read(Salaries)
read.table(Salaries)
read.csv(Salaries)
library(readr)
Salaries <- read_csv("Downloads/Salaries.csv")
View(Salaries)
library(readr)
Salaries <- read_csv("Downloads/Salaries.csv")
View(Salaries)
glimpse(Salaries)
library(dplyr)
glimpse(Salaries)
man1<-manova(cbind(yrs.since.phd, yrs.service, salary)~sex, data=Salaries)
summary(man1)
man1<-manova(cbind(yrs.since.phd, yrs.service, salary)~sex, data=Salaries)
summary(man1)
summary.aov(man1)
summary(man1)
summary.aov(man1)
Salaries%>%group_by(sex)%>%summarize(mean(yrs.since.phd),mean(yrs.service), mean(salary))
pairwise.t.test(Salaries$yrs.since.phd,Salaries$sex,
p.adj="none")
#p-value of .003
pairwise.t.test(Salaries$yrs.service,Salaries$sex,
p.adj="none")
#p-value of .0021
pairwise.t.test(Salaries$salary,Salaries$sex,
p.adj="none")
pairwise.t.test(Salaries$yrs.since.phd,Salaries$sex,
p.adj="none")
#p-value of .003
pairwise.t.test(Salaries$yrs.service,Salaries$sex,
p.adj="none")
#p-value of .0021
pairwise.t.test(Salaries$salary,Salaries$sex,
p.adj="none")
pairwise.t.test(Salaries$salary,Salaries$sex,
p.adj="none")
pairwise.t.test(Salaries$yrs.service,Salaries$sex,
p.adj="none")
.05/7
summary(man1)
summary.aov(man1)
.05/4
data("ToothGrowth")
view(ToothGrowth)
View(ToothGrowth)
#One way ANOVA Table
summary(aov(salary~rank,data=Salaries))
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/57)
})
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/57)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
```
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/57)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F)
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/57)
})
#One way ANOVA Table
summary(aov(salary~rank,data=Salaries))
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/384)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F)
Salaries$yrs.since.phd_c <- Salaries$yrs.since.phd - mean(Salaries$yrs.since.phd)
Salaries$yrs.service_c <- Salaries$yrs.service - mean(Salaries$yrs.service)
Salaries$salary_c <- Salaries$salary - mean(Salaries$salary)
fitsal1 <- lm(salary_c ~ yrs.service_c + yrs.since.phd_c + yrs.service_c*yrs.since.phd_c)
fitsal1 <- lm(salary_c ~ yrs.service_c + yrs.since.phd_c + yrs.service_c*yrs.since.phd_c, data = Salaries)
fitsal1
summary(fitsal1)
fitsal1 <- lm(salary ~ yrs.service_c + yrs.since.phd_c + yrs.service_c*yrs.since.phd_c, data = Salaries)
fitsal1
summary(fitsal1)
knitr::opts_chunk$set(echo = TRUE)
fit<-lm(BP ~ BMI + Glucose, data=meddat); summary(fit)
library(meddat)
fitsal1 <- lm(salary ~ yrs.service_c*yrs.since.phd_c, data = Salaries)
summary(fitsal1)
library(ggplot2)
ggPredict(fitsal1,colorAsFactor = TRUE,interactive=TRUE)
library(ggplot2)
ggPredict(fitsal1,colorAsFactor = TRUE,interactive=TRUE)
ggplot(Salaries,aes(y=salary,x=yrs.service_c,color=yrs.since.phd_c))+geom_point()+stat_smooth(method="lm",se=FALSE)
install.packages("devtools")
devtools::install_github("cardiomoon/ggiraphExtra")
knitr::opts_chunk$set(echo = TRUE)
#plot of regression:
library(interactions)
interact_plot(fitsal1, pred=yrs.service_c, modx=yrs.since.phd_c, plot.points = TRUE)
install.packages("jtools")
install.packages("jtools")
interact_plot(fitsal1, pred=yrs.service_c, m
interact_plot(fitsal1, pred=yrs.service_c, modx=yrs.since.phd_c, plot.points = TRUE)
interact_plot(fitsal1, pred = yrs.service_c, modx = yrs.since.phd_c, plot.points = TRUE)
install.packages("jtools")
devtools::install_github("jacob-long/jtools")
interact_plot(fitsal1, pred = yrs.service_c, modx = yrs.since.phd_c, plot.points = TRUE)
interact_plot(fitsal1, pred = yrs.service_c, modx = yrs.since.phd_c, plot.points = TRUE)
library(interactions)
install.packages("interactions")
library(interactions)
install.packages("interactions")
install.packages("interactions")
library(interactions)
library(interactions)
interact_plot(fitsal1, pred = yrs.service_c, modx = yrs.since.phd_c, plot.points = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(MASS)
library(ggplot2)
library(lmtest)
data<-biopsy%>%transmute(clump_thickness=V1,
cell_uniformity=V2,
marg_adhesion=V4,
bland_chromatin=V7,
outcome=class,
y=as.numeric(outcome)-1)
data<-biopsy%>%transmute(clump_thickness=V1,
cell_uniformity=V2,
marg_adhesion=V4,
bland_chromatin=V7,
outcome=class,
y=as.numeric(outcome)-1)
ggplot(data, aes(clump_thickness,y))+geom_jitter(aes(color=predicted),width=.3,height=0)+
stat_smooth(method="glm",method.args=list(family="binomial"),se=F)+ylab("malignancy (0,1)")
data$prob<-predict(fit,type="response") #get predicted probabilities
data$predicted<-ifelse(data$prob>.5,"malignant","benign") #predicted outcomes
ggplot(data, aes(clump_thickness,y))+geom_jitter(aes(color=predicted),width=.3,height=0)+
stat_smooth(method="glm",method.args=list(family="binomial"),se=F)+ylab("malignancy (0,1)")
#MANOVA test
man1<-manova(cbind(yrs.since.phd, yrs.service, salary)~sex, data=Salaries)
summary(man1)
#significant with a pvalue of 0.004884
#run univariate ANOVAs:
summary.aov(man1)
#All numeric variables have a significant mean difference across sex using an alpha value of .05.
#pairwaise t-tests:
Salaries%>%group_by(sex)%>%summarize(mean(yrs.since.phd),mean(yrs.service), mean(salary))
#Among females, the average salary is 101,002.40 while among males it is 115,090.40. Females have an average of 16.5 years since they recieved their PhD whereas males have 22.9 years since recieving theirs. On average, male professors have been teaching at the college for about 7 years longer as well.
#total number of tests performed- 1 MANOVA, 3 ANOVAs --> 4 total
#p-value to use: .007142857
.05/4
#.0125 --> everything still significant!
#A one-way multivariate analysis of variance was conducted to test the effect of gender on three numeric variables for professors of a particular college: number of years since recieving their PhD, number of years of service at the college, and nine month salary in dollars. Significant differences were found for one sex versus another on the basis of all three dependent variables with a pillai trace of .032223 and a pseudo F (3,393) of 4.3618. The p-value for this test was less than .05. To follow up with the MANOVA test, 3 univariate ANOVA tests were conducted, one for each dependnt variable. To control for Type 1 error rates becuase of multiple comparisons, the Bonferroni method was used to come up with a testable alpha value of .0125 based on the 4 total tests performed and an original alpha value of .05. The univariate ANOVAs were all found to be significant as well with p-values of .00296, .00213, and .0057 for years since Phd, years of service, and salary, respectively. The assumptions that were concluded to have been met for the MANOVA test performed are the multivariate normality of the dependent variables, the homogeneity of covarianc matrices for each depndent variable and between any 2, and the linear relationships between any two dependent variables. Just by looking at the data and making plots for the normalityassumptions, we can see that the assumptions are met.
#Randomization one way ANOVA test:
#One way ANOVA Table
summary(aov(salary~rank,data=Salaries))
# F value is 128.2
obs_F<-128.2
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/384)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F)
#The null hypothesis is that there is
#Linear regression model predicting salary from years since phd and years in service.
#mean centering of numeric variables
Salaries$yrs.since.phd_c <- Salaries$yrs.since.phd - mean(Salaries$yrs.since.phd)
Salaries$yrs.service_c <- Salaries$yrs.service - mean(Salaries$yrs.service)
Salaries$salary_c <- Salaries$salary - mean(Salaries$salary)
fitsal1 <- lm(salary ~ yrs.service_c*yrs.since.phd_c, data = Salaries)
fitsal1
summary(fitsal1)
#The interpretation of the output of this model is as follows:
#When the years since recieving their PhD is 0 and the years of service are also 0, we would expect a nine month salary of $123,533.470. When holding years since phd constant, for every increase in year of service we would expect an increase in salary of $250.528. When holding pears of service constant, we would expect a $1056.086 increase in salary for every additional year since phd. The negative interaction term shows that the higher the number of years since phd the less of an effect the number of years of service had on the salary.
#plot of regression:
install.packages("interactions")
library(interactions)
#Linear regression model predicting salary from years since phd and years in service.
#mean centering of numeric variables
Salaries$yrs.since.phd_c <- Salaries$yrs.since.phd - mean(Salaries$yrs.since.phd)
Salaries$yrs.service_c <- Salaries$yrs.service - mean(Salaries$yrs.service)
Salaries$salary_c <- Salaries$salary - mean(Salaries$salary)
fitsal1 <- lm(salary ~ yrs.service_c*yrs.since.phd_c, data = Salaries)
fitsal1
summary(fitsal1)
#The interpretation of the output of this model is as follows:
#When the years since recieving their PhD is 0 and the years of service are also 0, we would expect a nine month salary of $123,533.470. When holding years since phd constant, for every increase in year of service we would expect an increase in salary of $250.528. When holding pears of service constant, we would expect a $1056.086 increase in salary for every additional year since phd. The negative interaction term shows that the higher the number of years since phd the less of an effect the number of years of service had on the salary.
#plot of regression:
install.packages("interactions")
library(interactions)
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F)
Fs<-replicate(5000,{
new<-Salaries%>%mutate(salary=sample(salary))
SSW<- new%>%group_by(rank)%>%summarize(SSW=sum((salary-mean(salary))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(salary))%>%group_by(rank)%>%mutate(groupmean=mean(salary))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/2)/(SSW/384)
})
system("python \"Lab 13 SDS 348.R\"")
system("python \"Lab 13 SDS 348.R\"")
